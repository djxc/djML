# 视觉特征编码
数据维交通场景视频的视觉特征向量以及事件标签。需要学习视觉特征向量与事件标签之间的对应关系，并对视觉特征向量进行压缩重建。900段交通场景视频中提取的900段特征流数据以及对应的事件ID标签。每个特征文件对应一段特征流数据，包含250个特征向量。标注文件将由文本文件提供。文本文件每一行提供一个标注，标注格式为：文件名 ID。视觉特征数据值在0-10之内的浮点数据。数据集中的视觉特征向量应该是用其他网络模型提取的特征数据。
- 1、首先分析下数据分布  
对标签分析下共包含多少类别，每个类别的占比。{'1': 200, '2': 200, '3': 200, '4': 200, '0': 100}.可以看到0类数据较少，类别不均匀。每个数据为250*2048*1*1尺寸

- 2、可视化数据
将每个特征向量转换为250*2408尺寸的图片，查看不同类别的数据。看不出区别

- 3、拆分数据为训练集于测试集
每个类别按照7：3划分训练集于测试集。

- 4、模型选择
  - 4.1 多层感知机进行初步计算
把数据放入多层感知机需要太多的内存，不可行。
  - 4.2 循环神经网络
考虑到该数据是由视频获取到的，可能存在时序关系。可能是每个特征向量为一个时间点，一个特征数据流包含250个特征向量即为250个时间点。
  - 4.3 卷积神经网络
把特征数据流看为250*2408尺寸的单波段图片。
    首先采用LeNet结构训练，需要调整输入通道以及输出通道，网络结构增加多个卷积层、激活与池化块来缩小参数。模型参数很多，最后存储模型文件为1.3G，应该是全连接层参数太多，需要增加卷积层，减少全连接层参数。
    - 由于内存限制采用batchSize为4，在cpu下每个epoch需要四分钟。学习率设置为0.1，训练20epoch，loss不怎么下降。正确率也很低0.2左右。
    - 修改学习率为0.01：在20epoch内loss没有变化，1.6左右
    - 将lenet的激活函数修改为ReLU：loss明显下降。AlexNet与LeNet的一个区别就是采用了ReLU激活函数。sigmod激活函数可能会使梯度消失或梯度爆炸，相当于没有更新权重，导致loss没有变化，ReLU计算简单，仅会使一部分权重为0，有利于防止过拟合，又不会使所有的权重消失。loss从开始1.6下降到0.25，但在第25epoch之后loss突然上升到1.6，这应该是双下降，之后又下降了。50epoch loss在0.04左右，准确率在0.68左右。
    - 优化函数增加动量法，并增加学习率衰减：缓解参数震荡问题，loss会出现波动，但总体上会更快的趋于平稳。修改之后10epoch内loss没有下降，准确率很低，没有提升。应该是学习率设置太大了。
    - 降低学习率为0.001：loss下降在20epoch为0.9，准确率为0.55.学习率每10轮缩小10倍。收敛的很慢，可能学习率衰减的太快了。epoch30时精度在0.59，不怎么提升了。loss在0.7，下降很慢。验证集0.59准确率，在测试集上为0.63
    - 学习率衰减每30轮缩小10倍，batch_size设置为12：让学习率不下降的太快.batch_size会使模型收敛较慢。内存占用5G左右。在学习率缩小10倍之后loss下降很慢，每七八轮在下降0.01。100epoch，验证集精度0.637，loss：0.39，应该还有提升的趋势只是学习率太小了。
    - 学习率每10轮缩小10%，从30轮开始训练，初始学习率还是0.001.在40轮左右，准确率在0.67，loss在0.04左右。
    - 增加训练轮数，在150轮左右，学习率为0.009，准确率稳定在0.7左右，loss稳定在0.0026，不在下降，应该是学习率太大了。降低学习率为0.0001，loss还是在0.002不下降，准确率在0.7。测试集精度在0.72.
    - 数据归一化处理，学习率0.001，每30轮下降10%，batch_size为2，在38轮时学习率在0.72，之后学习率在0.69-0.7之前波动，loss在38轮在0.04，之后缓慢下降，在70轮到达0.002，之后下降缓慢。可能出现过拟合。数据归一化处理效果不明显。 
    - dropout，AlexNet与leNet区别为AlexNet在全连接层之间采用dropout，防止过拟合。dropout放在全连接层的激活之后。batch_size为16，学习率为0.1以及0.001时loss都不下降，准确率不提升。学习率调整为0.01，loss降低为0.01-0.02，准确率为0.7左右。
    - 修改网络结构，增加卷积层，减少全连接层的参数.增加两层卷积层，全连接层还是三层。学习率为0.0001，batch_size为16，50轮loss一直在1.6左右，准确率一直为0.1875，学习率调整为0.00001还是没有效果。将学习率修改为0.01，还是没有效果。
    - 学习率每10轮缩小10%，从30轮开始训练，初始学习率还是0.001.在40轮左右，准确率在0.67，loss在0.04左右。验证集0.68准确率，在测试集上为0.73
    - dropout，AlexNet与leNet区别为AlexNet在全连接层之间采用dropout，防止过拟合。
    - 使用预训练的resnet，使用预训练的resnet18，修改第一个卷积层因为输入为1波段图像，最后全连接层设置了两层，中间添加了一层dropout。学习率在0.001，batch size 为16，模型精度不稳定，0.4-0.5之间跳变，loss一直在下降。最后全连接层修改为一层,训练200轮，效果不明显，模型不稳定波动较大，准确率最高在0.5左右。resnet18参数不冻结，精度在0.68-0.7之间较为稳定。第一个全连接层指定权重，其他层固定权重，最后全连接层训练权重。


    - 使用修改后的AlexNet网络训练，6层卷积层，每层后跟ReLU以及最大池化层；全连接层4层，全连接层之间包含ReLU以及dropOut层，学习率设置为0.001，batch_size为8,好像没有学习到东西，不清楚原因。
    - 使用修改后的LeNet网络结构，四层卷积网络，每层后跟ReLU以及最大池化层；全连接层4层，全连接层之间包含ReLU以及dropOut层；（原始的LeNet网络卷积层是2层，全连接层3层，卷积层之后为平均池化层。激活函数为Sigmod，没有dropout层）。学习率设置为0.001，每10轮下降0.9，batch_size为16。没有数据增强。
  
  | 轮数 | 验证精度 | loss | 学习率 |
  | ---  | ---     | ---  | ---   |
  | 25   | 0.198   | 1.53 | 0.00081    |
  | 50   | 0.47    | 1.2  | 0.00059    |
  | 70   | 0.6     | 0.714 | 0.0005    |
  | 100   | 0.6875   | 0.198 | 0.00035 |
  | 130  | 0.6912  |  0.08  | 0.00028 |
  | 150  | 0.68    |  0.06  | 0.00021 | 


    - 在70轮左右验证集精度达到0.6，学习率在0.0005，模型稳定性较好，验证集精度波动不大，loss还在下降。在100轮验证集精度在0.69，学习率在0.00035，loss在0.2左右还呈现下降趋势；
    - 训练集的loss与验证集loss不同，这是正常现象，只要二者趋势相同即可。

  | 轮数 | 验证精度 | 训练loss | 验证loss | 学习率 |
  | ---  | ---     |   ---   |  ---     |  ---   |
  | 25   | 0.25    | 1.53    |  1.599   | 0.001  |
  | 50   | 0.637   | 1.022   |  0.846   | 0.001  |
  | 70   | 0.66    | 0.27    |  1.2     | 0.001  |
  | 100  | 0.739   | 0.03    |  1.68    | 0.0009 |
  | 130  | 0.7138  |  0.049  |  2.194   | 0.0009 |
  | 150  | 0.721    |  0.041  |  2.148   | 0.0009 |

- 修改后的LeNet，batch_size为12，学习率每100轮下降0.9。取130轮验证集精度最高的，
cls 0 acc is 0.593, total: 27, error: 11
cls 1 acc is 0.810, total: 63, error: 12
cls 2 acc is 0.810, total: 63, error: 12
cls 3 acc is 0.882, total: 51, error: 6
cls 4 acc is 0.627, total: 67, error: 25
train acc: 0.7428, loss: 2.0864;
测试机上为0.725，测试集0类或4类较多，而模型对这两类精度较低，可以采用focalloss进行优化。

cls 0 acc is 0.630, total: 27, error: 10
cls 1 acc is 0.841, total: 63, error: 10
cls 2 acc is 0.794, total: 63, error: 13
cls 3 acc is 0.902, total: 51, error: 5
cls 4 acc is 0.716, total: 67, error: 19
验证集精度为0.7716，测试集精度为0.765，0类精度太低

cls 0 acc is 0.593, total: 27, error: 11
cls 1 acc is 0.841, total: 63, error: 10
cls 2 acc is 0.825, total: 63, error: 11
cls 3 acc is 0.902, total: 51, error: 5
cls 4 acc is 0.731, total: 67, error: 18 280轮
验证集精度为0.7826，测试集精度为0.775，0类精度太低

无数据增强lenet：
cls 0 acc is 0.808, total: 26, error: 5
cls 1 acc is 0.706, total: 68, error: 20
cls 2 acc is 0.722, total: 54, error: 15
cls 3 acc is 0.792, total: 48, error: 10
cls 4 acc is 0.533, total: 75, error: 35
60轮，验证集精度为0.6838，测试集精度为0.7325，0类权重较大

cls 0 acc is 0.808, total: 26, error: 5
cls 1 acc is 0.779, total: 68, error: 15
cls 2 acc is 0.778, total: 54, error: 12
cls 3 acc is 0.750, total: 48, error: 12
cls 4 acc is 0.560, total: 75, error: 33
90轮，验证集精度0.7132，测试集精度0.7475

- 5、数据增强，如何进行？
  - 1、垂直方向为时间方向，是否可以随机减少某些帧数据，对数据不会改变本质。随机裁剪对模型好像效果不明显。增加mixup效果明显，验证集精度稳定在0.76-0.78之间。最好0.7754，0类为0.63；4类为0.716
  - 2、概率垂直翻转，事件可能是堵车、车祸，时间的正反应该不会改变其事件的本质。
  - 3、mixup
  lenet无数据增强精度最高在0.7多一点，采用mixup数据增强最高可达0.713， 采用数据增强精度可到达0.77-0.78

- 6、使用k折交叉验证
将train.csv中每类取一半作为验证集，之前的验证集合并到train.csv中

- 7、分析每个类的错误率
0与4类错误率较高, 0类与4类之间不好区分，发生误判可能性较大。

- 8、loss下降但是准确率不提升
过拟合、数据没有格式化、数据集没有打乱、网络结构有问题

- 9、loss不下降
网络结构有问题、激活函数存在问题、训练时间不够、权重初始化问题、正则化问题、优化器问题、学习率问题、梯度消失或爆炸、batchsize太小会导致loss波动，难以收敛、数据集存在噪音异常值、特征选择不对

- 10、过拟合
在优化器中添加权重衰减超参数，weight_decay；droupOut层，测试需要关闭droupOut层，调用net.eval()即可。
  - 10.1 设置权重衰减，0.0001
  - 10.2 增加归一化层。

- 11、类别不均匀，难易程度不同
采用focalloss损失函数，五类权重分别设置0.4， 0.1， 0.1， 0.1， 0.3，学习率0.001，训练500轮，没有效果。 