{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interation: 0, loss: 8.145128930554039, w: 0.9822406284088075, b: 0.0004636170984777005\n",
      "interation: 50, loss: 0.0011597734068617845, w: 1.4769904141393744, b: 0.05656007484290752\n",
      "interation: 100, loss: 0.0002423091374761839, w: 1.4770190214748495, b: 0.07723921627682867\n",
      "interation: 150, loss: 0.00012062010536763872, w: 1.4770294400552493, b: 0.08477040693289756\n",
      "interation: 200, loss: 0.0001044797269031638, w: 1.4770332344253203, b: 0.0875132109743178\n",
      "interation: 250, loss: 0.00010233892742056139, w: 1.4770346163068901, b: 0.08851211995872504\n",
      "interation: 300, loss: 0.00010205497977740142, w: 1.4770351195779567, b: 0.08887591523686417\n",
      "interation: 350, loss: 0.00010201731802313095, w: 1.477035302865564, b: 0.0890084067916126\n",
      "interation: 400, loss: 0.00010201232270878638, w: 1.4770353696175575, b: 0.08905665923779457\n",
      "interation: 450, loss: 0.00010201166014896044, w: 1.4770353939281409, b: 0.08907423242249277\n",
      "interation: 500, loss: 0.00010201157226949951, w: 1.477035402781876, b: 0.08908063244663396\n",
      "interation: 550, loss: 0.00010201156061349762, w: 1.4770354060063409, b: 0.08908296328818097\n",
      "interation: 600, loss: 0.0001020115590674886, w: 1.477035407180667, b: 0.08908381216346604\n",
      "interation: 650, loss: 0.00010201155886243221, w: 1.477035407608348, b: 0.08908412131757842\n",
      "interation: 700, loss: 0.00010201155883523337, w: 1.4770354077641064, b: 0.08908423390922394\n",
      "interation: 750, loss: 0.00010201155883162604, w: 1.4770354078208323, b: 0.08908427491427016\n",
      "interation: 800, loss: 0.00010201155883114818, w: 1.4770354078414916, b: 0.08908428984800523\n",
      "interation: 850, loss: 0.00010201155883108333, w: 1.4770354078490153, b: 0.08908429528676133\n",
      "interation: 900, loss: 0.00010201155883107539, w: 1.4770354078517556, b: 0.08908429726751613\n",
      "interation: 950, loss: 0.00010201155883107484, w: 1.4770354078527537, b: 0.0890842979888924\n",
      "Final loss: 0.000102011558831074, w: 1.4770354078531127, b: 0.08908429824854137\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# y = 1.477x + 0.089\n",
    "#\n",
    "import numpy as np\n",
    "data = []  # 列表，用来保存样本数据\n",
    "for i in range(1000):\n",
    "    x = np.random.uniform(-10., 10.)  # 通过均匀分布获取(-10, 10)之间的数据\n",
    "    eps = np.random.normal(0., 0.01)  # 均值为0，方差为0.01随机采样噪音\n",
    "    y = 1.477 * x + 0.089 + eps\n",
    "    data.append([x, y])\n",
    "data = np.array(data)   # 将数组转换为numpy数组\n",
    "\n",
    "def mse(b, w, points):\n",
    "    \"\"\"计算真实值与预测值的误差\"\"\"\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        totalError += (y - (w*x + b))**2    # 计算样本与实际值之间的误差，并叠加\n",
    "    return totalError/float(len(points))\n",
    "\n",
    "def step_gradient(b_current, w_current, points, lr):\n",
    "    \"\"\"求导，计算导数，然后更新b，w\"\"\"\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    M = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        b_gradient += (2/M) * ((w_current * x + b_current) - y)\n",
    "        w_gradient += (2/M) * x * ((w_current * x + b_current) - y)\n",
    "    new_b = b_current - (lr * b_gradient)\n",
    "    new_w = w_current - (lr * w_gradient)\n",
    "    return [new_b, new_w]\n",
    "\n",
    "def gradient_desent(points, starting_b, starting_w, lr, num_iterations):\n",
    "    \"\"\"反向传播算法\"\"\"\n",
    "    b = starting_b\n",
    "    w = starting_w\n",
    "    for step in range(num_iterations):\n",
    "        b, w = step_gradient(b, w, np.array(points), lr)\n",
    "        loss = mse(b, w, points)\n",
    "        if step % 50 ==0:\n",
    "            print(f\"interation: {step}, loss: {loss}, w: {w}, b: {b}\")\n",
    "    return [b, w]\n",
    "\n",
    "def main():\n",
    "    lr = 0.01\n",
    "    initial_b = 0\n",
    "    initial_w = 0\n",
    "    num_interations = 1000\n",
    "    [b, w] = gradient_desent(data, initial_b, initial_w, lr, num_interations)\n",
    "    loss = mse(b, w, data)\n",
    "    print(f'Final loss: {loss}, w: {w}, b: {b}')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
